{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AoCuiXVuA8QJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ordered SGD on classification w/ pytorch\n",
        "by Dizhi Ma"
      ],
      "metadata": {
        "id": "nT7ih0cQAssI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define some util function\n",
        "Here are some utility functions for the experiments"
      ],
      "metadata": {
        "id": "AoCuiXVuA8QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "9TJP6yS0CWe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        self.memory = 100\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def get_data(type='MINIST'):\n",
        "    batch_size_train, batch_size_test = 128, 1000 \n",
        "    data_path = '/data'\n",
        "\n",
        "    if type == 'CIFAR10':\n",
        "        epoch = 50\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "        train_data = torchvision.datasets.CIFAR10(data_path, train=True, download=True, transform=train_transform)\n",
        "        test_data = torchvision.datasets.CIFAR10(data_path, train=False, download=True, transform=train_transform)\n",
        "\n",
        "    elif type == 'CIFAR100':\n",
        "        epoch = 50\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "        ])\n",
        "        train_data = torchvision.datasets.CIFAR100(data_path, train=True, download=True, transform=train_transform)\n",
        "        test_data = torchvision.datasets.CIFAR100(data_path, train=False, download=True, transform=train_transform)\n",
        "    \n",
        "    elif type == 'MNIST':\n",
        "        train_transform = transforms.Compose([\n",
        "                            transforms.Grayscale(num_output_channels=3),\n",
        "                            transforms.ToTensor()       \n",
        "                       ])                \n",
        "        train_data = torchvision.datasets.MNIST(data_path, train=True, download=True, transform=train_transform)\n",
        "        test_data = torchvision.datasets.MNIST(data_path, train=False, download=True, transform=train_transform)\n",
        "    \n",
        "    elif type == 'FashionMINST':\n",
        "        train_transform = transforms.Compose([\n",
        "                            transforms.Grayscale(num_output_channels=3),\n",
        "                            transforms.ToTensor()       \n",
        "                       ])   \n",
        "\n",
        "        train_data = torchvision.datasets.FashionMNIST(data_path, train=True, download=True, transform=train_transform)\n",
        "        test_data = torchvision.datasets.FashionMNIST(data_path, train=False, download=True, transform=train_transform)\n",
        "    \n",
        "    elif type == 'SVHN':\n",
        "        train_transform = transforms.Compose([\n",
        "                            transforms.Grayscale(num_output_channels=3),\n",
        "                            transforms.ToTensor()       \n",
        "                       ])   \n",
        "\n",
        "        train_data = torchvision.datasets.SVHN(data_path, split='train', download=True, transform=train_transform)\n",
        "        test_data = torchvision.datasets.SVHN(data_path, split='test', download=True, transform=train_transform)\n",
        "    \n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_test, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "class OurCNN(nn.Module): \n",
        "\n",
        "    def __init__(self):\n",
        "        super(OurCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d( 3, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d( 8, 16, kernel_size=3)\n",
        "        self.fc = nn.Linear(576, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b,_,_,_ = x.size()\n",
        "        x = self.conv1(x)        \n",
        "        x = F.relu(F.max_pool2d(x,2)) \n",
        "\n",
        "        x = self.conv2(x)        \n",
        "        x = F.relu(F.max_pool2d(x,2)) \n",
        "\n",
        "        x = x.view(b, -1)      \n",
        "        x = self.fc(x)\n",
        "        return x \n",
        "\n",
        "class trainer:\n",
        "    def __init__(self, model='resnet18', dataset='CIFAR10', q=None, adaptive=False, base_lr=0.01):\n",
        "        if model == 'resnet18':\n",
        "            model = models.resnet18(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'mobilenet_v2':\n",
        "            model = models.mobilenet_v2(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'OurNN':\n",
        "            model = OurCNN().cuda()\n",
        "        \n",
        "        self.classifier = model\n",
        "        self.base_lr = base_lr\n",
        "        self.optimizer = optim.SGD(self.classifier.parameters(), lr=self.base_lr, momentum=0.8)\n",
        "        self.dataset = dataset\n",
        "        self.train_loader, self.test_loader = get_data(dataset)\n",
        "        self.q = q\n",
        "        self.adaptive = adaptive\n",
        "\n",
        "    def train(self, epoch, q, best_acc):\n",
        "\n",
        "        self.classifier.train() \n",
        "        loss_func = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "        pbar = tqdm(enumerate(self.train_loader))\n",
        "        count = 0\n",
        "        correct = 0\n",
        "        train_losses = AverageMeter()\n",
        "        train_acc = AverageMeter()\n",
        "\n",
        "        for batch_idx, (images, targets) in pbar:\n",
        "\n",
        "            images, targets = images.cuda(), targets.cuda()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.classifier(images)\n",
        "            loss = loss_func(output, targets) \n",
        "\n",
        "            bs = images.size()[0]\n",
        "            count += bs\n",
        "            ssize = bs if not q else q(bs, best_acc)\n",
        "\n",
        "            loss = torch.mean(torch.sort(loss, dim=0, descending=True)[0][:min(ssize, bs)], dim=0)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1] \n",
        "            correct += pred.eq(targets.data.view_as(pred)).sum() \n",
        "\n",
        "            train_losses.update(loss.item())\n",
        "            train_acc.update(correct/count)\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                b_size = ssize\n",
        "            pbar.set_description(f'Epoch {epoch} [{count}/{len(self.train_loader.dataset)}]: bs:{b_size} Loss: {train_losses.avg:.2f} Acc: {100.*correct/count:.2f}%')\n",
        "\n",
        "        return train_losses.avg, correct/count\n",
        "\n",
        "    def test(self, epoch):\n",
        "\n",
        "        self.classifier.eval() \n",
        "        loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        test_losses = AverageMeter()\n",
        "        pbar = tqdm(self.test_loader)\n",
        "        with torch.no_grad():\n",
        "            for images, targets in pbar:\n",
        "                # count_b += 1\n",
        "                images, targets = images.cuda(), targets.cuda()\n",
        "                output = self.classifier(images)\n",
        "                test_loss = loss_func(output, targets).item()\n",
        "                test_losses.update(test_loss)\n",
        "                pred = output.data.max(1, keepdim=True)[1] \n",
        "                correct += pred.eq(targets.data.view_as(pred)).sum() \n",
        "                bs = images.size()[0]\n",
        "                count += bs\n",
        "                pbar.set_description(f'Epoch {epoch} [{count}/{len(self.test_loader.dataset)}]:Loss: {test_losses.avg:.2f} Acc: {100.*correct/count:.2f}%')\n",
        "\n",
        "        test_loss = test_losses.avg\n",
        "\n",
        "        return 100.*correct/len(self.test_loader.dataset)\n",
        "    \n",
        "    def fit(self):\n",
        "        train_acces = []\n",
        "        test_accs = []\n",
        "        max_epoch = 20 # if self.dataset not in ['CIFAR100'] else 50\n",
        "\n",
        "        start = time.time()\n",
        "        best_acc = 0\n",
        "        best_test = 0\n",
        "        for epoch in range(1, max_epoch+1):\n",
        "            if self.q is None and not self.adaptive:\n",
        "                q = None\n",
        "            elif self.adaptive:\n",
        "                q = adaptive_q(best_acc)\n",
        "            else:\n",
        "                q = self.q\n",
        "\n",
        "            loss, acc = self.train(epoch, q, best_acc)\n",
        "            test_acc = self.test(epoch)\n",
        "\n",
        "            best_acc = max(acc, best_acc)\n",
        "            best_test = max(best_test, test_acc)\n",
        "            train_acces.append(acc)\n",
        "            test_accs.append(test_acc)\n",
        "            if epoch == max_epoch-10:\n",
        "                self.base_lr /= 10\n",
        "                self.optimizer = optim.SGD(self.classifier.parameters(), lr=self.base_lr, momentum=0.8)\n",
        "        print(f'\\nbest acc {best_test}% time used {time.time()-start:.2f}')\n",
        "        return train_acces, test_accs\n",
        "\n",
        "class trainerPlus:\n",
        "    def __init__(self, model='resnet18', dataset='CIFAR10', q=None, adaptive=False, base_lr=0.01):\n",
        "        if model == 'resnet18':\n",
        "            model = models.resnet18(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'mobilenet_v2':\n",
        "            model = models.mobilenet_v2(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(pretrained=True)\n",
        "            model = model.cuda()\n",
        "        elif model == 'OurNN':\n",
        "            model = OurCNN().cuda()\n",
        "        \n",
        "        self.classifier = model\n",
        "        self.base_lr = base_lr\n",
        "        self.optimizer = optim.SGD(self.classifier.parameters(), lr=self.base_lr, momentum=0.8)\n",
        "        self.dataset = dataset\n",
        "        self.train_loader, self.test_loader = get_data(dataset)\n",
        "        self.q = q\n",
        "        self.adaptive = adaptive\n",
        "\n",
        "    def train(self, epoch, q, best_acc):\n",
        "\n",
        "        self.classifier.train() \n",
        "        loss_func = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "        pbar = tqdm(enumerate(self.train_loader))\n",
        "        count = 0\n",
        "        correct = 0\n",
        "        train_losses = AverageMeter()\n",
        "        train_acc = AverageMeter()\n",
        "\n",
        "        for batch_idx, (images, targets) in pbar:\n",
        "\n",
        "            images, targets = images.cuda(), targets.cuda()\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.classifier(images)\n",
        "            loss = loss_func(output, targets) \n",
        "\n",
        "            bs = images.size()[0]\n",
        "            count += bs\n",
        "            ssize = bs if not q else q(bs, best_acc)\n",
        "\n",
        "            loss = torch.mean(torch.sort(loss, dim=0, descending=True)[0][:min(ssize, bs)], dim=0)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1] \n",
        "            correct += pred.eq(targets.data.view_as(pred)).sum() \n",
        "\n",
        "            train_losses.update(loss.item())\n",
        "            train_acc.update(correct/count)\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                b_size = ssize\n",
        "                adaptive_lr = self.base_lr*np.sqrt(ssize/bs)\n",
        "                self.optimizer = optim.SGD(self.classifier.parameters(), lr=adaptive_lr, momentum=0.8)\n",
        "            pbar.set_description(f'Epoch {epoch} [{count}/{len(self.train_loader.dataset)}]: bs:{b_size} Loss: {train_losses.avg:.2f} Acc: {100.*correct/count:.2f}%')\n",
        "\n",
        "        return train_losses.avg, correct/count\n",
        "\n",
        "    def test(self, epoch):\n",
        "\n",
        "        self.classifier.eval() \n",
        "        loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        test_losses = AverageMeter()\n",
        "        pbar = tqdm(self.test_loader)\n",
        "        with torch.no_grad():\n",
        "            for images, targets in pbar:\n",
        "                # count_b += 1\n",
        "                images, targets = images.cuda(), targets.cuda()\n",
        "                output = self.classifier(images)\n",
        "                test_loss = loss_func(output, targets).item()\n",
        "                test_losses.update(test_loss)\n",
        "                pred = output.data.max(1, keepdim=True)[1] \n",
        "                correct += pred.eq(targets.data.view_as(pred)).sum() \n",
        "                bs = images.size()[0]\n",
        "                count += bs\n",
        "                pbar.set_description(f'Epoch {epoch} [{count}/{len(self.test_loader.dataset)}]:Loss: {test_losses.avg:.2f} Acc: {100.*correct/count:.2f}%')\n",
        "\n",
        "        test_loss = test_losses.avg\n",
        "\n",
        "        return 100.*correct/len(self.test_loader.dataset)\n",
        "    \n",
        "    def fit(self):\n",
        "        train_acces = []\n",
        "        test_accs = []\n",
        "        max_epoch = 20 # if self.dataset not in ['CIFAR100'] else 50\n",
        "\n",
        "        start = time.time()\n",
        "        best_acc = 0\n",
        "        best_test = 0\n",
        "        for epoch in range(1, max_epoch+1):\n",
        "            if self.q is None and not self.adaptive:\n",
        "                q = None\n",
        "            elif self.adaptive:\n",
        "                q = adaptive_q(best_acc)\n",
        "            else:\n",
        "                q = self.q\n",
        "\n",
        "            loss, acc = self.train(epoch, q, best_acc)\n",
        "            test_acc = self.test(epoch)\n",
        "\n",
        "            best_acc = max(acc, best_acc)\n",
        "            best_test = max(best_test, test_acc)\n",
        "            train_acces.append(acc)\n",
        "            test_accs.append(test_acc)\n",
        "            if epoch == max_epoch-10:\n",
        "                self.base_lr = 0.001\n",
        "        print(f'\\nbest acc {best_test}% time used {time.time()-start:.2f}')\n",
        "        return train_acces, test_accs"
      ],
      "metadata": {
        "id": "uiE-4476A7c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## q-value strategy (fixed and adaptive)\n",
        "Here, we define q value strategy used in the experiments"
      ],
      "metadata": {
        "id": "TyzSmGX2Zcdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix(num):\n",
        "    def q(bs, epoch):\n",
        "        return num\n",
        "    return q\n",
        "\n",
        "def adaptive_q(acc):\n",
        "    train_acc = acc*100\n",
        "    if train_acc >= 99.5:\n",
        "        def q(bs, epoch):\n",
        "            return max(bs // 16, 4)\n",
        "    elif train_acc >= 95:\n",
        "        def q(bs, epoch):\n",
        "            return max(bs // 8, 8)\n",
        "    elif train_acc >= 90:\n",
        "        def q(bs, epoch):\n",
        "            return max(bs // 4,16)\n",
        "    elif train_acc >= 80:\n",
        "        def q(bs, epoch):\n",
        "            return max(bs // 2, 32)\n",
        "    else:\n",
        "        def q(bs, epoch):\n",
        "            return bs\n",
        "    return q"
      ],
      "metadata": {
        "id": "-bi_9rcOGi2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "8ALfZ7RdZm53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments with adptive q"
      ],
      "metadata": {
        "id": "CYdNVlV3zauv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_cifar10 = trainer(dataset='CIFAR10').fit()\n",
        "sgd_cifar100 = trainer(dataset='CIFAR100').fit()\n",
        "sgd_MNIST = trainer(dataset='MNIST').fit()\n",
        "sgd_svhn = trainer(dataset='SVHN').fit()"
      ],
      "metadata": {
        "id": "icVGi2xxPMR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qsgd_cifar10 = trainer(dataset='CIFAR10', adaptive=True).fit()\n",
        "qsgd_cifar100 = trainer(dataset='CIFAR100', adaptive=True).fit()\n",
        "qsgd_MNIST = trainer(dataset='MNIST', adaptive=True).fit()\n",
        "qsgd_svhn = trainer(dataset='SVHN', adaptive=True).fit()"
      ],
      "metadata": {
        "id": "p-2HnTLYWfdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_cifar10_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR10').fit()\n",
        "sgd_cifar100_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR100').fit()\n",
        "sgd_MNIST_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='MNIST').fit()\n",
        "sgd_svhn_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='SVHN').fit()"
      ],
      "metadata": {
        "id": "gS1N37tou3Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qsgd_cifar10_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR10', adaptive=True).fit()\n",
        "qsgd_cifar100_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR100', adaptive=True).fit()\n",
        "qsgd_MNIST_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='MNIST', adaptive=True).fit()\n",
        "qsgd_svhn_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='SVHN', adaptive=True).fit()"
      ],
      "metadata": {
        "id": "yGyX1DbvuIW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ablation study on fixed q"
      ],
      "metadata": {
        "id": "NKg_qEG2zoGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qsgd_96 = trainer(dataset='CIFAR10', q=fix(96)).fit()\n",
        "qsgd_64 = trainer(dataset='CIFAR10', q=fix(64)).fit()\n",
        "qsgd_32 = trainer(dataset='CIFAR10', q=fix(32)).fit()"
      ],
      "metadata": {
        "id": "HfUKaY1aNEev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qsgd_96_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR10', q=fix(96)).fit()\n",
        "qsgd_64_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR10', q=fix(64), base_lr=0.003).fit()\n",
        "qsgd_32_mobilenet_v2 = trainer(model='mobilenet_v2', dataset='CIFAR10', q=fix(32), base_lr=0.003).fit()"
      ],
      "metadata": {
        "id": "IQv1vh6bbeW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improvement with learning rate scheme"
      ],
      "metadata": {
        "id": "j1UXXU5rz2po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qsgd_plus_96_mobilenet_v2 = trainerPlus(model='mobilenet_v2', dataset='CIFAR10', q=fix(96)).fit()\n",
        "qsgd_plus_64_mobilenet_v2 = trainerPlus(model='mobilenet_v2', dataset='CIFAR10', q=fix(64)).fit()\n",
        "qsgd_plus_32_mobilenet_v2 = trainerPlus(model='mobilenet_v2', dataset='CIFAR10', q=fix(32)).fit()"
      ],
      "metadata": {
        "id": "Q0uebBdjmowu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "EHLMx_zYZuLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_cmap(n, name='hsv'):\n",
        "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
        "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
        "    return plt.cm.get_cmap(name, n)\n",
        "\n",
        "length = 20\n",
        "cmap = get_cmap(6)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "\n",
        "ax = fig.add_subplot(2,1,1)\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_cifar10[0]],\n",
        "        linewidth = '2',color='k', label='SGD')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_cifar10[0]],\n",
        "        linewidth = '2',color='r', label='OSGD')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_96[0]],\n",
        "        linewidth = '2',color=cmap(2), label='OSGD q=96')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_64[0]],\n",
        "        linewidth = '2',color=cmap(3), label='OSGD q=64')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_32[0]],\n",
        "        linewidth = '2',color=cmap(4), label='OSGD q=32')\n",
        "# ax.set_xlabel('epoch', fontsize=20)\n",
        "ax.set_ylabel('train accuracy(%)', fontsize=20)\n",
        "# ax.set_title(f'Accuracy', fontsize=15)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,1,2)\n",
        "ax.plot(range(length),[d.item() for d in sgd_cifar10[1]],\n",
        "        linewidth = '2',color='k', label='SGD')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_cifar10[1]],\n",
        "        linewidth = '2',color='r', label='OSGD')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_96[1]],\n",
        "        linewidth = '2',color=cmap(2), label='OSGD q=96')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_64[1]],\n",
        "        linewidth = '2',color=cmap(3), label='OSGD q=64')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_32[1]],\n",
        "        linewidth = '2',color=cmap(4), label='OSGD q=32')\n",
        "ax.set_xlabel('epoch', fontsize=20)\n",
        "ax.set_ylabel('test accuracy(%)', fontsize=20)\n",
        "# ax.set_title(f'Accuracy', fontsize=15)\n",
        "ax.legend(prop={'size': 18})\n",
        "\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FkpwTkX5NE_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_cmap(n, name='hsv'):\n",
        "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
        "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
        "    return plt.cm.get_cmap(name, n)\n",
        "\n",
        "length = 20\n",
        "cmap = get_cmap(4)\n",
        "fig = plt.figure(figsize=(12, 12))\n",
        "\n",
        "ax = fig.add_subplot(2,1,1)\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_96_mobilenet_v2[0]],'--',\n",
        "        linewidth = '2',color='k', label='OSGD q=96')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_plus_96_mobilenet_v2[0]],\n",
        "        linewidth = '2',color='k', label='OSGD q=96*')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_64_mobilenet_v2[0]],'--',\n",
        "        linewidth = '2',color='r', label='OSGD q=64')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_plus_64_mobilenet_v2[0]],\n",
        "        linewidth = '2',color='r', label='OSGD q=64*')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_32_mobilenet_v2[0]],'--',\n",
        "        linewidth = '2',color='g', label='OSGD q=32')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_plus_32_mobilenet_v2[0]],\n",
        "        linewidth = '2',color='g', label='OSGD q=32*')\n",
        "# ax.set_xlabel('epoch', fontsize=20)\n",
        "ax.set_ylabel('train accuracy(%)', fontsize=20)\n",
        "# ax.set_title(f'Accuracy', fontsize=15)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,1,2)\n",
        "ax.plot(range(length),[d.item() for d in qsgd_96_mobilenet_v2[1]],'--',\n",
        "        linewidth = '2',color='k', label='OSGD q=96')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_plus_96_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='k', label='OSGD q=96*')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_64_mobilenet_v2[1]],'--',\n",
        "        linewidth = '2',color='r', label='OSGD q=64')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_plus_64_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='r', label='OSGD q=64*')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_32_mobilenet_v2[1]],'--',\n",
        "        linewidth = '2',color='g', label='OSGD q=32')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_plus_32_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='g', label='OSGD q=32*')\n",
        "ax.set_xlabel('epoch', fontsize=20)\n",
        "ax.set_ylabel('test accuracy(%)', fontsize=20)\n",
        "# ax.set_title(f'Accuracy', fontsize=15)\n",
        "ax.legend(prop={'size': 18})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UJ7cqVmqz4Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = 20\n",
        "cmap = get_cmap(2)\n",
        "f_size = 30\n",
        "fig = plt.figure(figsize=(48, 15))\n",
        "ax = fig.add_subplot(2,4,1)\n",
        "ax.plot(range(length),[d.item() for d in sgd_cifar10[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_cifar10[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_cifar10[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_cifar10[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "# ax.set_xlabel('epoch', fontsize=f_size)\n",
        "ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'CIFAR10 & ResNet18', fontsize=f_size)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,4,5)\n",
        "ax.plot(range(length),[d.item() for d in sgd_cifar10_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_cifar10_mobilenet_v2[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_cifar10_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_cifar10_mobilenet_v2[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "ax.set_xlabel('epoch', fontsize=f_size)\n",
        "ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'CIFAR10 & MobileNetV2', fontsize=f_size)\n",
        "\n",
        "ax = fig.add_subplot(2,4,2)\n",
        "ax.plot(range(length),[d.item() for d in sgd_cifar100[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_cifar100[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_cifar100[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_cifar100[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "# ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'CIFAR100 & ResNet18', fontsize=f_size)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,4,6)\n",
        "ax.plot(range(length),[d.item() for d in sgd_cifar100_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_cifar100_mobilenet_v2[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_cifar100_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_cifar100_mobilenet_v2[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'CIFAR100 & MobileNetV2', fontsize=f_size)\n",
        "\n",
        "ax = fig.add_subplot(2,4,3)\n",
        "ax.plot(range(length),[d.item() for d in sgd_MNIST[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_MNIST[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_MNIST[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_MNIST[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "# ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'MNIST & ResNet18', fontsize=f_size)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,4,7)\n",
        "ax.plot(range(length),[d.item() for d in sgd_MNIST_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_MNIST_mobilenet_v2[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_MNIST_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_MNIST_mobilenet_v2[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'MNIST & MobileNetV2', fontsize=f_size)\n",
        "# ax.legend(prop={'size': 18})\n",
        "\n",
        "ax = fig.add_subplot(2,4,4)\n",
        "ax.plot(range(length),[d.item() for d in sgd_svhn[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_svhn[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_svhn[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_svhn[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "# ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'SVHN & ResNet18', fontsize=f_size)\n",
        "# ax.legend(prop={'size': 20})\n",
        "\n",
        "ax = fig.add_subplot(2,4,8)\n",
        "ax.plot(range(length),[d.item() for d in sgd_svhn_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='k', label='SGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in sgd_svhn_mobilenet_v2[0]], 'k--',\n",
        "        linewidth = '2',color='k', label='SGD train')\n",
        "ax.plot(range(length),[d.item() for d in qsgd_svhn_mobilenet_v2[1]],\n",
        "        linewidth = '2',color='r', label='OSGD test')\n",
        "ax.plot(range(length),[d.item()*100 for d in qsgd_svhn_mobilenet_v2[0]], 'r--',\n",
        "        linewidth = '2',color='r', label='OSGD train')\n",
        "ax.set_xlabel('epoch', fontsize=f_size)\n",
        "# ax.set_ylabel('accuracy(%)', fontsize=f_size)\n",
        "ax.set_title(f'SVHN & MobileNetV2', fontsize=f_size)\n",
        "ax.legend(prop={'size': f_size})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UKIHFuW4q6M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReLU Linear Regression Via ordered SGD (Preliminary Implemetation)"
      ],
      "metadata": {
        "id": "BsQbNTRm7Fly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from numpy.core.fromnumeric import mean\n",
        "import random"
      ],
      "metadata": {
        "id": "aXMLodwtB_gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        self.memory = 100\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def ReLU(x):\n",
        "    return x * (x > 0)\n",
        "\n",
        "def predict(x,w):\n",
        "    return ReLU(w.dot(x))\n",
        "\n",
        "def full_q(e, epochs, batch_size):\n",
        "    return batch_size\n",
        "\n",
        "def naive_q(e, epochs, batch_size):\n",
        "    return batch_size//2\n",
        "\n",
        "def Train(data,w_star,epochs, lr, batch_size=64, mode='0'):\n",
        "    '''\n",
        "    regular SGD training\n",
        "    input:\n",
        "        data  :nparray Nxd \n",
        "        w     :nparray d\n",
        "        epoch :int\n",
        "        lr    :float\n",
        "        batch_size: int\n",
        "        mode  :'0' for replacement, '1' for no replacement\n",
        "    '''\n",
        "    train_error=[]\n",
        "    smooth_error = []\n",
        "    #initialize\n",
        "    w=np.random.randn(data[0].shape[0])\n",
        "    b=np.random.randn(1)\n",
        "    noise = np.random.randn(2000)*(0.05)**2\n",
        "    order=list(range(len(data)))\n",
        "    order_list = []\n",
        "    while len(order_list) < epochs*batch_size:\n",
        "        order_list +=random.sample(order, len(order))\n",
        "\n",
        "    train_losses = AverageMeter()\n",
        "    batch_losses = AverageMeter()\n",
        "    pbar = tqdm(range(epochs))\n",
        "    for e in pbar:\n",
        "        dw = [] # cache dw\n",
        "        batch_losses = AverageMeter()\n",
        "        for b in range(batch_size):\n",
        "            i = random.choice(order)\n",
        "            a = predict(data[i],w)\n",
        "            l = (predict(data[i],w_star)+noise[i]) - a\n",
        "            dw.append(lr*l*data[i]*(a>0)) # gradient is 0 if a<0\n",
        "            train_losses.update(l**2)\n",
        "            batch_losses.update(l**2)\n",
        "        dw = np.array(dw)\n",
        "        w += np.mean(dw, axis=0)\n",
        "        train_error.append(train_losses.avg)\n",
        "        smooth_error.append(batch_losses.avg)\n",
        "\n",
        "        if batch_size == 1:\n",
        "            pbar.set_description(f\"epoch:{e} loss:{train_losses.avg}\")\n",
        "        else:\n",
        "            pbar.set_description(f\"epoch:{e} loss:{batch_losses.avg}\")\n",
        "        \n",
        "    return [train_error, smooth_error]\n",
        "\n",
        "def TrainOSGD(data,w_star,epochs, lr, batch_size=64, strategy=naive_q):\n",
        "    '''\n",
        "    input:\n",
        "        data  :nparray Nxd \n",
        "        w     :nparray d\n",
        "        epoch :int\n",
        "        lr    :float\n",
        "        batch_size: int\n",
        "        mode  :'0' for replacement, '1' for no replacement\n",
        "    '''\n",
        "    train_error=[]\n",
        "    smooth_error = []\n",
        "    #initialize\n",
        "    w=np.random.randn(data[0].shape[0])\n",
        "    b=np.random.randn(1)\n",
        "    noise = np.random.randn(2000)*(0.05)**2\n",
        "    order=list(range(len(data)))\n",
        "    order_list = []\n",
        "    while len(order_list) < epochs*batch_size:\n",
        "        order_list +=random.sample(order, len(order))\n",
        "    train_losses = AverageMeter()\n",
        "    batch_losses = AverageMeter()\n",
        "    pbar = tqdm(range(epochs))\n",
        "    for e in pbar:\n",
        "        dw = [] # cache dw\n",
        "        loss_batch = []\n",
        "        batch_losses = AverageMeter()\n",
        "        for b in range(batch_size):\n",
        "            i = random.choice(order)\n",
        "            a = predict(data[i],w)\n",
        "            l = (predict(data[i],w_star)+noise[i]) - a\n",
        "            loss_batch.append(l.item()**2)\n",
        "            dw.append(lr*l*data[i]*(a>0))\n",
        "            train_losses.update(l**2)\n",
        "            batch_losses.update(l**2)\n",
        "        \n",
        "        q = strategy(e, epochs, len(loss_batch))        \n",
        "\n",
        "        q_idx = np.argsort(np.array(loss_batch),axis=0)[-q:]\n",
        "        dw = np.array(dw)[q_idx]\n",
        "\n",
        "        w += np.mean(dw, axis=0)\n",
        "        train_error.append(train_losses.avg)\n",
        "        smooth_error.append(batch_losses.avg)\n",
        "        pbar.set_description(f\"epoch:{e} qvalue: {q} loss:{batch_losses.avg:.6f}\")\n",
        "\n",
        "    return [train_error, smooth_error]\n",
        "\n",
        "\n",
        "def plot_mistake(trainError,filename='1'):\n",
        "    '''\n",
        "    plot a figure for error vs epochs\n",
        "    '''\n",
        "    length=len(trainError[0])\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(range(length),trainError[0],\n",
        "            linewidth = '2',color='b',label='SGD training data error')\n",
        "    ax.plot(range(length),trainError[1],\n",
        "            linewidth = '2',color='G',label='Order-SGD training data error')\n",
        "    ax.set_xlabel('iter', fontsize=20)\n",
        "    ax.set_ylabel('loss', fontsize=20)\n",
        "\n",
        "    ax.set_title(f'{filename}', fontsize=15)\n",
        "    ax.legend(prop={'size': 15})"
      ],
      "metadata": {
        "id": "l2WwkpdWiY6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d, N, T, lr, b_size = 500, 2000, 2000, 5e-2, 100\n",
        "x = np.random.randn(N, d)\n",
        "e = np.random.randn(N, 1)*(0.05)\n",
        "w_star = np.random.randn(d)\n",
        "\n",
        "error,_ = TrainOSGD(x,w_star,T,lr, b_size, full_q)\n",
        "OSGD_error,_ = TrainOSGD(x,w_star,T,lr, b_size)\n",
        "\n",
        "plot_mistake([error, OSGD_error], 'loss vs iter')"
      ],
      "metadata": {
        "id": "Ky9PKZ238wok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
